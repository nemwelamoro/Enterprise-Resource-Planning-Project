#import needed libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
df = pd.read_csv("C:/Users/FBI/Desktop/Tarus project/erp dataset.csv")
df.head()

# Check the structure of the dataset
print(df.info())

# Summary statistics
print(df.describe())

# Check for missing values
print(df.isnull().sum())

#drop missing values
df = df.dropna(subset=['Work Experience'])


#Frequency distributions tables of different variables in the dataset
from collections import Counter


# Create a frequency distribution table for Level of Education
frequency_table = Counter(df['Level of Education'])

total = len(df['Level of Education'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table Work Experience
frequency_table = Counter(df['Work Experience'])

total = len(df['Work Experience'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for System Navigation Statement 1 
frequency_table = Counter(df['System Navigation Statement 1'])

total = len(df['System Navigation Statement 1'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for System Navigation Statement 2
frequency_table = Counter(df['System Navigation Statement 2'])

total = len(df['System Navigation Statement 2'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for System Navigation Statement 3
frequency_table = Counter(df['System Navigation Statement 3'])

total = len(df['System Navigation Statement 3'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for System Navigation Statement 4
frequency_table = Counter(df['System Navigation Statement 4'])

total = len(df['System Navigation Statement 4'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')

# Create a frequency distribution table for System Presentation Statement 1
frequency_table = Counter(df['System Presentation Statement 1'])

total = len(df['System Presentation Statement 1'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for System Presentation Statement 2
frequency_table = Counter(df['System Presentation Statement 2'])

total = len(df['System Presentation Statement 2'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for System Presentation Statement 3
frequency_table = Counter(df['System Presentation Statement 3'])

total = len(df['System Presentation Statement 3'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for System Presentation Statement 4
frequency_table = Counter(df['System Presentation Statement 4'])

total = len(df['System Presentation Statement 4'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for Security Statement 1
frequency_table = Counter(df['Security Statement 1'])

total = len(df['Security Statement 1'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for Security Statement 2
frequency_table = Counter(df['Security Statement 2'])

total = len(df['Security Statement 2'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for Security Statement 3
frequency_table = Counter(df['Security Statement 3'])

total = len(df['Security Statement 3'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for Security Statement 4
frequency_table = Counter(df['Security Statement 4'])

total = len(df['Security Statement 4'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for User Knowledge Statement 1
frequency_table = Counter(df['User Knowledge Statement 1'])

total = len(df['User Knowledge Statement 1'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for User Knowledge Statement 2
frequency_table = Counter(df['User Knowledge Statement 2'])

total = len(df['User Knowledge Statement 2'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for User Knowledge Statement 3
frequency_table = Counter(df['User Knowledge Statement 3'])

total = len(df['User Knowledge Statement 3'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for User Knowledge Statement 4
frequency_table = Counter(df['User Knowledge Statement 4'])

total = len(df['User Knowledge Statement 4'])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)')


# Create a frequency distribution table for Academic Service Delivery
frequency_table = Counter(df['Academic Service Delivery '])

total = len(df['Academic Service Delivery '])

# Print the frequency distribution table with percentages
for level, count in frequency_table.items():
    percentage = (count / total) * 100
    print(f'{level}: {count} ({percentage:.2f}%)') 


# Visualization of academic service delivery scores
plt.figure(figsize=(10, 6))
sns.histplot(df['Academic Service Delivery '], kde=True)
plt.title('Academic Service Delivery Scores Distribution')
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.show()


# Visualization of System Navigation Satisfaction
plt.figure(figsize=(10, 6))
sns.histplot(df['System Navigation Satisfaction'], kde=True)
plt.title('System Navigation Satisfaction Distribution')
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.show()


# Visualization of System Navigation Satisfaction
plt.figure(figsize=(10, 6))
sns.histplot(df['System Presentation Satisfaction'], kde=True)
plt.title('System Presentation Distribution')
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.show()


# Visualization of System Security Satisfaction
plt.figure(figsize=(10, 6))
sns.histplot(df['Security Satisfaction'], kde=True)
plt.title('System Security Satisfaction Distribution')
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.show()


# Visualization of User Knowledge Satisfaction
plt.figure(figsize=(10, 6))
sns.histplot(df['User Knowledge Satisfaction'], kde=True)
plt.title('User Knowledge Satisfaction Distribution')
plt.xlabel('Score')
plt.ylabel('Frequency')
plt.show()

#Create a correlation heatmap for a subset of our dataset
# Import necessary libraries
import matplotlib.pyplot as plt
import seaborn as sns

# Define the subset of variables
subset_variables = ['System Navigation Satisfaction', 'System Presentation Satisfaction', 'Security Satisfaction', 'User Knowledge Satisfaction', 'Academic Service Delivery ']

# Create a subset DataFrame with only the selected variables
subset_df = df[subset_variables]

# Calculate the correlation matrix for the subset
correlation_matrix = subset_df.corr()

# Create the correlation heatmap
plt.figure(figsize=(10, 8))  # You can adjust the figure size as needed
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

# Define the threshold
threshold = 5

# Transform the dependent variable into 'Low' and 'High'
df['Academic Service Delivery '] = df['Academic Service Delivery '].apply(lambda x: 'Low' if x < threshold else 'High')

# Split the data into independent (X) and dependent (y) variables
X = df[['System Navigation Satisfaction','System Presentation Satisfaction', 'Security Satisfaction','User Knowledge Satisfaction']]
y = df['Academic Service Delivery ']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


from sklearn.preprocessing import StandardScaler

# Create a StandardScaler object
scaler = StandardScaler()

# Fit the scaler to your training data and transform it
X_train_scaled = scaler.fit_transform(X_train)

# Transform your test data using the same scaler
X_test_scaled = scaler.transform(X_test)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

# Create and fit the Logistic Regression model
model = LogisticRegression()
model.fit(X_train[['System Navigation Satisfaction']], y_train)
# Make predictions
y_pred = model.predict(X_test[['System Navigation Satisfaction']])

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred,zero_division=1)

print("Accuracy:", accuracy)
print("Classification Report:\n", report)


from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, roc_auc_score

# Make predictions with the best model
y_pred =model.predict(X_test[['System Navigation Satisfaction']])

# Compute the confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred)

# Compute precision, recall, F1-score, and support for each class
precision, recall, f1_score, support = precision_recall_fscore_support(y_test, y_pred,zero_division=1)

# Compute the ROC AUC score (only for binary classification)
roc_auc = roc_auc_score(y_test,model.predict_proba(X_test[['System Navigation Satisfaction']])[:,1])

# Print the metrics
print("Confusion Matrix:\n", conf_matrix)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1_score)
print("Support:", support)
print("ROC AUC Score:", roc_auc)